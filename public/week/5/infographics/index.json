[{"content":"Goals for this week  getting our Github accounts set up and making our first log entries getting Hypothes.is set up getting Zotero installed   learn how to describe what\u0026rsquo;s gone wrong, and to figure out how to fix it   explore our ignorance: what is dighist?  Listen  intro podcast  Read These readings have two aims. One, to ground the fact of the digital in the physicality of the world; Two, to give you a sense of the potentials. Most are fairly short.\n  Lorna Richardson, 2020 \u0026lsquo;Digital tech \u0026amp; the environment\u0026rsquo; #DHGoesVIRAL. Right-Click on the date in the tweet below to open the thread:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  I start by acknowledging the horrific human cost of the Corvid-19 pandemic \u0026amp; the dedication of our underfunded, under resourced healthcare services. My paper today is about digital tech \u0026amp; the environment, \u0026amp; reflects on the structural effects of current isolation 1/20 #DHGoesVIRAL\n\u0026mdash; Lorna Richardson (@lornarichardson) April 2, 2020   Kate Crawford and Vladan Joler, 2018. \u0026lsquo;Anatomy of an AI System\u0026rsquo; anatomyof.ai\n  Brian Croxall, Quinn Warnick, 2020. \u0026lsquo;Failure\u0026rsquo; MLA Digital Pedagogy in the Humanities. Just read the curatorial statement.\n  My entry in the same volume on \u0026lsquo;History\u0026rsquo; MLA Digital Pedagogy in the Humanities. Just read the curatorial statement.\n  Sharon Leon, 2016.\u0026lsquo;Returning Women to the History of Digital History\u0026rsquo; [bracket]\n  Since pretty much everyone under quarantine has to use digitized primary sources, I thought it might be useful to point to #digitalarchives that *explicitly* acknowledge \u0026amp; caution users abt #archivalsilences in their contents, and describe their work to rectify them.\nA thread.\n\u0026mdash; Amalia Skarlatou Levi (@amaliasl) April 2, 2020   Read the full thread by Amalia Skarlatou Levi and explore links of interest; annotate anything interesting you find with Hypothes.is in our group keeping in mind what you\u0026rsquo;ve already heard/read. Share anything interesting you\u0026rsquo;ve found in our social space. A handy getting-started approach to annotation is to think of the three W\u0026rsquo;s: the weird, the wonderful, the worrying. Also add anything you read or anything interesting you find to your Zotero library.\n  Tim Hitchcock, 2013 \u0026lsquo;Big Data for Dead People\u0026rsquo; Historyonics\n  Matthew Lincoln, 2015 \u0026lsquo;Confabulation in the humanities\u0026rsquo; blog\n  Do   Follow the instructions for Setting Up Github, Setting up Hypothesis, Setting up Zotero, and asking for help. You should read the discord page if you\u0026rsquo;re new to that platform.\n  Log your reflection in your appropriate github repository\n  When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!\n  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice.\r Record and Reflect   Being a digital historian means keeping track of what you\u0026rsquo;ve done, as a gift to your future self (ie, so that when you come back to something, you can pick up where you left off). Make a new text document, and put into it any new terms you\u0026rsquo;ve encountered, commands you used, error messages you encountered, websites that helped, and so on: this document is a scrap book, as it were. Bullet points and memos-to-self are fine. Put this text document into your week one repo on github, along with any other files or digital things you happen to make. Call it your \u0026lsquo;notes.md\u0026rsquo;.\n  In a new text document, jot down some reflections -narrative, or bullet points, both are fine. Call it \u0026lsquo;journal.md\u0026rsquo; This document also goes into your week one repo on github. Detail any issues you had with getting started, any parts that caused you difficulty. If you got any error messages while trying to get set up, copy those into your reflection; google them. Do you find any websites that help you? What kind of \u0026lsquo;failures\u0026rsquo; might you have encountered this week?\n  Drawing on your annotations of what you\u0026rsquo;ve read (and/or your notes from what you\u0026rsquo;ve listened to), discuss your idea of what \u0026lsquo;digital history\u0026rsquo; might be prior to starting this course, and think through whether any of the materials we\u0026rsquo;ve seen this week confirm or upset those notions. What kinds of \u0026lsquo;digital silences\u0026rsquo; did you encounter? What has excited you? Finally, where do you want to go, with digital history?\nSubmit Work You can submit the link to your work on this form\n","description":"An overview of DigHist","id":0,"section":"week","tags":null,"title":"Instructions: May 4","uri":"https://craftingdh.netlify.com/week/1/instructions/"},{"content":"Goals for this week  learn some of the ways historical information is made available digitally, paying attention to disparities of labour, and of tech  Listen Read Something given. That\u0026rsquo;s a nice way of thinking about it. Of course, much of the data that we are \u0026lsquo;given\u0026rsquo; wasn\u0026rsquo;t really given willingly. When we topic model Martha Ballard\u0026rsquo;s diary, did she give this to us? Of course, she couldn\u0026rsquo;t have imagined what we might try to do to it. Other kinds of data - census data, for instance - were compelled: folks had to answer the questions, on pain of punishment. This is all to suggest that there is a moral dimension to what we do with big data in history. Johanna Drucker famously framed it as data versus capta, or \u0026lsquo;things captured.\u0026rsquo;\nThis week, we\u0026rsquo;re thinking about some of the ways historical materials find their ways online, and we\u0026rsquo;re learning some of the ways we can pull that information onto our own machines for our own research. Read these two pieces discussing the way the Transcribe Bentham project organized the digitization of Bentham\u0026rsquo;s papers.\n  Causer, Tim, Grint, Kris, Sichani, Anna-Maria and Terras, Melissa, ”Making such bargain: Transcribe Bentham and the quality and cost-effectiveness of crowdsourced transcription’, Digital Scholarship in the Humanities, 33:3 2018, pp. 467-87 . Open access version.\n  Causer, Tonra, \u0026amp; Wallace, 2012. Transcription maximized; expense minimized? Crowdsourcing and editing The Collected Works of Jeremy Bentham LLC 27.2\n  Do Try to work through as many of these exercises as you can. Don\u0026rsquo;t worry too much if you get stuck: the point is to push yourself beyond your current level of ability. You are not grade on how many of these you do, but rather on how you push your development as a digital historian: and that journey looks different for each of you.\n Download and install the Sublime Text Editor Install Conda Download web materials with wget Retrieve materials from the Chronicling America API Use OCR (Object Character Recognition) to turn images of text into text  Bonus:\n Download videos with youtube-dl Transcribe audio from videos and other sources automatically   When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice. Remember: it\u0026rsquo;s not how many you do, it\u0026rsquo;s that you pushed yourself that matters.\r Record and Reflect   As you did for week one, make another notes.md entry and put it in your repo for week 2.\n  In your journal.md for this week, think about, who pays for work to end up online? Who does the work? What are some of the ethical dimensions of doing this work? Does Carleton give you any resources for getting those materials onto your own machine in formats you can read? What are some of the barriers to accessing the resources that Carleton does make available to you? Where do you fit into this digital history machine? Put your journal.md into your github repo for week 2.\n  Submit work You can submit the link to your work on this form\n","description":"Basic Tools","id":1,"section":"week","tags":null,"title":"Instructions: May 11","uri":"https://craftingdh.netlify.com/week/2/instructions/"},{"content":"The 18th is the Long Weekend. Take a break from your school work, if you can.\r Goals for this week Listen Read Do  Learn how to transform a text file using Regular Expressions   When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice. Remember: it\u0026rsquo;s not how many you do, it\u0026rsquo;s that you pushed yourself that matters.\r Record and Reflect   As you did for week one, make another notes.md entry and put it in your repo for week 3.\n  In your journal.md for this week, think about\n  Submit work You can submit the link to your work on this form\n","description":"Basic Tools Encore","id":2,"section":"week","tags":null,"title":"Instructions: May 19","uri":"https://craftingdh.netlify.com/week/3/instructions/"},{"content":"Goals for this week Listen Read Do  When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice. Remember: it\u0026rsquo;s not how many you do, it\u0026rsquo;s that you pushed yourself that matters.\r Record and Reflect   As you did in previous weeks, make another notes.md entry and put it in your repo for week 4.\n  In your journal.md for this week, think about\n  Submit work You can submit the link to your work on this form\n","description":"Of Macroscopes and Microscopes","id":3,"section":"week","tags":null,"title":"Instructions: May 25","uri":"https://craftingdh.netlify.com/week/4/instructions/"},{"content":"Goals for this week Listen Read Do  When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice. Remember: it\u0026rsquo;s not how many you do, it\u0026rsquo;s that you pushed yourself that matters.\r Record and Reflect   As you did for the previous weeks, make another notes.md entry and put it in your repo for week 5.\n  In your journal.md for this week, think about\n  Submit work You can submit the link to your work on this form\n","description":"Telling the Compelling Story","id":4,"section":"week","tags":null,"title":"Instructions: June 1","uri":"https://craftingdh.netlify.com/week/5/instructions/"},{"content":"Introduction Cost = $0.\nAnaconda is a platform for data science work. By installing Anaconda, you get access to a series of tools for working in both the Python and R programming languages, plus excellent visual interfaces that reduce (some of) the pain of programming.\nWhen we do work in python, we sometimes need to add more lego-pieces to what we\u0026rsquo;re doing, to accomplish specific tasks. Anaconda comes with very nearly - but not all - of the pieces you might need. The thing is, different tasks might require the same pieces, and if you\u0026rsquo;ve ever fought with a sibling over who gets the good lego piece, well, that\u0026rsquo;s what can happen inside your machine. Anaconda keeps everything playing nice by allowing us to create environments with copies of the pieces we need, separate from other copies, so that there are no conflicts.\nAnaconda also gives us some excellent user interfaces for doing our work - juypter notebooks and R Studio - for instance. In this course, we\u0026rsquo;ll use R Studio a bit, and we\u0026rsquo;ll take a look at some jupyter notebooks, but we\u0026rsquo;ll mostly use python at the command line.\nDownload Download Anaconda From Here\nDouble-click the downloaded file to install.\nAccept all of the defaults during the installation. (More info on the installation process is here).\nAnaconda comes with something called \u0026lsquo;Anaconda Navigator\u0026rsquo;, which looks like this:\nPowershell and Terminal We may occasionally launch some of these apps (eg, Jupyter Notebooks, R Studio). For now, we\u0026rsquo;ll be using the command line. Windows users in particular: we\u0026rsquo;ll be using the \u0026lsquo;powershell\u0026rsquo;. You can click on the \u0026lsquo;Powershell Prompt\u0026rsquo; in Anaconda Navigator. You can also find it by searching your pc for \u0026lsquo;Anaconda Powershell\u0026rsquo;.\n  When I ask you to use the command prompt, Windows users: I mean anaconda powershell.\n  Mac users can use the terminal (which you can find under applications -\u0026gt; other -\u0026gt; terminal).\n  Going forward, when I want you to enter code at the command prompt or terminal prompt, I will signal this by starting the line with a $, like this:\n$ echo \u0026quot;this is what it looks like\u0026quot;\nYou do not type the $.\nOpen a command prompt or terminal now and confirm that anaconda is installed:\n$ conda --version\nand that python is installed:\n$ python --version\nif you get an error message, then anaconda did not install correctly or Windows users you might not be in anaconda powershell.\nWhen we type \u0026lsquo;conda\u0026rsquo; or \u0026lsquo;python\u0026rsquo; or indeed \u0026lsquo;echo\u0026rsquo; or anything else at the prompt, we are telling the computer that this is a command. If we want the machine to run a particular python program we\u0026rsquo;ve written, we would invoke python followed by the program name, eg example.py so that the machine knows to open example.py with python.\nNavigating the Commandline When you click on a file in your windows explorer or in mac\u0026rsquo;s finder, you click through nested folders, right? The path you take through those folders will look something like this: username\\example-folder\\a-subfolder\\file.txt, although finder or explorer by default don\u0026rsquo;t show you that.\nWhen you open anaconda powershell or the terminal, how do you know where you are at? You print the working directory:\n$ pwd\nand that will give you the path to where you are working. To see what\u0026rsquo;s inside the folder, you can:\n$ ls list files, on a Mac or\n$ dir directory, on a PC\nFiles will have an extension (eg, .txt, .doc) while directories won\u0026rsquo;t. To go into a directory, we change directories:\n$ cd subfolder\nand we can go back up a level:\n$ cd ..\nMy terminal, demonstrating a bit of moving around. Also some of the contents of my machine.\n","description":"instructions","id":5,"section":"week","tags":null,"title":"Setting up Anaconda","uri":"https://craftingdh.netlify.com/week/2/installing-anaconda/"},{"content":"If any of the instructions below are unclear, annotate this page with hypothesis while being logged into our course reading group. If you spot someone asking for help and you can offer advice, respond to the annotation. Introduction Github is a code sharing website often used by digital historians. \u0026lsquo;Git\u0026rsquo; is a program that takes snapshots of the current state of a folder, and stores them in sequence, allowing you to revert your changes to an earlier state. It also allows you to create branches, or duplicates of your folder, so you can experiment. If you like the results of your work, you can merge that branch back into your original.\nGithub therefore is a hub for sharing these git snapshots.\nA branch (a copy, a duplicate) of your work uploaded to Github could therefore be copied to say my account (a fork); then I might download to my machine to work on it (I\u0026rsquo;ve pulled it). Once I\u0026rsquo;m happy with my changes, I commit them (save them to the sequence of changes that Git tracks), and then I could push those changes to the fork in my account. I would then send you a pull notice, asking you to pull my changes back to your account; you could then decide whether or not to merge.\nFor our purposes, you will use Github mostly as a place to put your reflections or other pieces of work. I might sometimes fork your work, pull it down onto my machine, make changes that I commit, push it back online, and ask you to pull the changes back. But that won\u0026rsquo;t happen very often. It takes a while to get comfortable with this.\nGet your account  Got to github.com and sign up for an account. You don\u0026rsquo;t have to use your real name. (Protip: You might want to set up an email just for signing up for things.)  Verify your account.  Select the free tier (nb: I will never require you to pay for any reading, or any software. If something wants you to pay, stop and ask for help).  Skip telling Github anything about yourself.  Do the verification email thing. Once you hit the verification link in your email, you\u0026rsquo;ll be brought back to Github to make a new repository:  Give it a reasonable name; tick the \u0026lsquo;initialize with a readme\u0026rsquo; box, and hit the green commit button:  And on the final page, hit the \u0026lsquo;dismiss\u0026rsquo; button in the \u0026lsquo;Github Actions box\u0026rsquo;  Ta Da! You now have a github account, and you\u0026rsquo;ve created your first repository. Going Forward create a new repository for each week\u0026rsquo;s work/reflection. You can create a new repository from the plus sign in the top right corner:\nnb Remember to tick off the \u0026lsquo;initialize with a readme.md\u0026rsquo; file.\nOnce you\u0026rsquo;ve done that, you\u0026rsquo;ll be at your Github user page:\nSetting up a \u0026lsquo;repository\u0026rsquo; for your work A \u0026lsquo;repository\u0026rsquo; is just a folder that you\u0026rsquo;ve shared on Github. There are two ways to do this; the easy way and the more complex way. Luck you, you have already done the easy way - you selected the initialize with a readme, and it\u0026rsquo;s already present in your browser!\nTo create new repositories, just click on the + button on the top right of your Github page when you\u0026rsquo;re logged in. You might want to go ahead now and create repositories for week 2 through to week 6. Remember to tick off the initialize with a readme box. But if you didn\u0026rsquo;t tick the initialize box, you\u0026rsquo;ve embarked on the more complex way. In the screenshot below, I created a new repository but I forgot to initialize it, and now I\u0026rsquo;m looking at this page:\nIf this is you, do not despair.\nWhen you\u0026rsquo;ve forgotten to initialize a new repo:  If you have a PC, click on this link to download and install git. Make a new directory on your computer with the same name as the repo you created above. In my example, that would be week-two. On a PC, right-click on the folder and select \u0026lsquo;open a command prompt here\u0026rsquo;. On a Mac, go to System Preferences, select Keyboard \u0026gt; Shortcuts \u0026gt; Services. Look for \u0026lsquo;New Terminal at Folder\u0026rsquo; and tick the box. Open your finder; find the folder you created, right-click and select \u0026lsquo;open Terminal here\u0026rsquo;. Do you see where, in your browser at github, it says ...or create a new repository on the command line? Type in each line exactly as it is there (beginning with echo), hitting enter at the end of each line, in order. If the command works, you\u0026rsquo;ll just be presented with the next prompt. The computer only ever responds when there is output to print - which often means only when there is an error message to report.  Ta da! You can now go to github.com\\\u0026lt;your-user-name\u0026gt;\\your-repo and you\u0026rsquo;ll see it all there tickety boo.\nMaking a new text file on Github You can make a new text file by clicking on the \u0026lsquo;create new file\u0026rsquo; button; remember to always use .md as the file extension. You can specify headers, links, images, bullets, blockquotes and so on by using markdown conventions\nThe two videos below might be a bit clearer on youtube itself.\n  Uploading a file into Github You can add new files from your computer by dragging and dropping them into the main repository. At the end of this video, I show you how to display the image in the text of the reflection.\n  Going further Github can also be used to run an entire website, generated from your text files. In fact, that\u0026rsquo;s how I built this course website! The following three links are from my HIST4806a 2020 seminar on digital history and museums; they will walk you through how to use your Github account to serve up a professional scholarly website; you can use this scholarly website to host your reflections and course work, if you want. Follow these three pages in order:\n  Building Your Own Scholarly Website\n  Customizing Your Scholarly Website\n  Updating Your Scholarly Website\n  ","description":"instructions","id":6,"section":"week","tags":null,"title":"Setting up your Github","uri":"https://craftingdh.netlify.com/week/1/github/"},{"content":"Introduction A regular expression (also called regex) is a powerful tool for finding and manipulating text. At its simplest, a regular expression is just a way of looking through texts to locate patterns. When you search a website for instance (use ctrl+f in most applications to search, by the way), the search box finds exact matches; there\u0026rsquo;s no room for fuzziness. A regular expression on the other hand can help you find every line that begins with a number, or every instance of an email address, or whenever a word is used even if there are slight variations in how it\u0026rsquo;s spelled. As long as you can describe the pattern you\u0026rsquo;re looking for, regular expressions can help you find it. Once you\u0026rsquo;ve found your patterns, they can then help you manipulate your text so that it fits just what you need.\nRegular expressions can look pretty complex, but once you know the basic syntax and vocabulary, simple ‘regexes’ will be easy. Regular expressions can often be used right inside the \u0026lsquo;Find and Replace\u0026rsquo; box in many text and document editors, such as Sublime Text, Atom, or Notepad++. You cannot use Microsoft Word, however!\nNB In text editors, you have to indicate that you wish to do a regex search. In Sublime Text, you open the search panel from the \u0026lsquo;Find\u0026rsquo; menu (or use the shortcut) and then you need to tick the box that has .* in the search panel to enable regular expression searches.\nSome basic principles Protip: there are libraries of regular expressions, online. For example, if you want to find all postal codes, you can search “regular expression Canadian postal code” and learn what ‘formula’ to search for to find them.\nAlso, here is a cheatsheet for regular expressions in Sublime Text.\nLet\u0026rsquo;s say you\u0026rsquo;re looking for all the instances of \u0026ldquo;cat\u0026rdquo; or \u0026ldquo;dog\u0026rdquo; in your document. When you type the vertical bar on your keyboard (it looks like |, shift+backslash on windows keyboards), that means \u0026lsquo;or\u0026rsquo; in regular expressions. So, if your query is dog|cat and you press \u0026lsquo;find\u0026rsquo;, it will show you the first time either dog or cat appears in your text.\nIf you want to replace every instance of either \u0026ldquo;cat\u0026rdquo; or \u0026ldquo;dog\u0026rdquo; in your document with the world \u0026ldquo;animal\u0026rdquo;, you would open your find-and-replace box, put dog|cat in the search query, put animal in the \u0026lsquo;replace\u0026rsquo; box, hit \u0026lsquo;replace all\u0026rsquo;, and watch your entire document fill up with references to animals instead of dogs and cats.\nThe astute reader will have noticed a problem with the instructions above; simply replacing every instance of \u0026ldquo;dog\u0026rdquo; or \u0026ldquo;cat\u0026rdquo; with \u0026ldquo;animal\u0026rdquo; is bound to create problems. Simple searches don\u0026rsquo;t differentiate between letters and spaces, so every time \u0026ldquo;cat\u0026rdquo; or \u0026ldquo;dog\u0026rdquo; appear within words, they\u0026rsquo;ll also be replaced with \u0026ldquo;animal\u0026rdquo;. \u0026ldquo;catch\u0026rdquo; will become \u0026ldquo;animalch\u0026rdquo;; \u0026ldquo;dogma\u0026rdquo; will become \u0026ldquo;animalma\u0026rdquo;; \u0026ldquo;certificate\u0026rdquo; will become \u0026ldquo;certifianimale\u0026rdquo;. In this case, the solution appears simple; put a space before and after your search query, so now it reads:\ndog | cat\nWith the spaces, \u0026ldquo;animal\u0026rdquo; replace \u0026ldquo;dog\u0026rdquo; or \u0026ldquo;cat\u0026rdquo; only in those instances where they\u0026rsquo;re definitely complete words; that is, when they\u0026rsquo;re separated by spaces.\nThe even more astute reader will notice that this still does not solve our problem of replacing every instance of \u0026ldquo;dog\u0026rdquo; or \u0026ldquo;cat\u0026rdquo;. What if the word comes at the beginning of a line, so it is not in front of a space? What if the word is at the end of a sentence or a clause, and thus followed by a punctuation? Luckily, in the language of regex, you can represent the beginning or end of a word using special characters.\n\\\u0026lt;\nmeans the beginning of a word. In some programs, you might use this alternative:\n\\b\nso if you search for \\\u0026lt;cat , (or, as it may be, \\bcat )it will find \u0026ldquo;cat\u0026rdquo;, \u0026ldquo;catch\u0026rdquo;, and \u0026ldquo;catsup\u0026rdquo;, but not \u0026ldquo;copycat\u0026rdquo;, because your query searched for words beginning with \u0026ldquo;cat\u0026rdquo;. For patterns at the end of the line, you would use:\n\\\u0026gt; or \\b\nagain. If you therefore searched:\ncat\\\u0026gt;\nit will find \u0026ldquo;cat\u0026rdquo; and \u0026ldquo;copycat\u0026rdquo;, but not \u0026ldquo;catch,\u0026rdquo; because your query searched for words ending with -\u0026ldquo;cat\u0026rdquo;.\nRegular expressions can be mixed, so if you wanted to find words only matching \u0026ldquo;cat\u0026rdquo;, no matter where in the sentence, you\u0026rsquo;d search for\n\\\u0026lt;cat\\\u0026gt;\nwhich would find every instance. And, because all regular expressions can be mixed, if you searched for\n\\\u0026lt;cat|dog\\\u0026gt;\nand replaced all with \u0026ldquo;animal\u0026rdquo;, you would have a document that replaced all instances of \u0026ldquo;dog\u0026rdquo; or \u0026ldquo;cat\u0026rdquo; with \u0026ldquo;animal\u0026rdquo;, no matter where in the sentence they appear. You can also search for variations within a single word using parentheses. For example if you were looking for instances of \u0026ldquo;gray\u0026rdquo; or \u0026ldquo;grey\u0026rdquo;, instead of the search query\ngray|grey\nyou could type\ngr(a|e)y\ninstead. The parentheses signify a group, and like the order of operations in arithmetic, regular expressions read the parentheses before anything else. Similarly, if you wanted to find instances of either \u0026ldquo;that dog\u0026rdquo; or \u0026ldquo;that cat\u0026rdquo;, you would search for:\n(that dog)|(that cat)\nNotice that the vertical bar | can appear either inside or outside the parentheses, depending on what you want to search for.\nThe period character . in regular expressions directs the search to just find any character at all. For example, if we searched for:\nd.g\nthe search would return \u0026ldquo;dig\u0026rdquo;, \u0026ldquo;dog\u0026rdquo;, \u0026ldquo;dug\u0026rdquo;, and so forth.\nAnother special character from our cheat sheet, the plus symbol + instructs the program to find any number of the previous character. If we search for\ndo+g\nit would return any words that looked like \u0026ldquo;dog\u0026rdquo;, \u0026ldquo;doog\u0026rdquo;, \u0026ldquo;dooog\u0026rdquo;, and so forth. Adding parentheses before the plus would make a search for repetitions of whatever is in the parentheses, for example querying\n(do)+g\nwould return \u0026ldquo;dog\u0026rdquo;, \u0026ldquo;dodog\u0026rdquo;, \u0026ldquo;dododog\u0026rdquo;, and so forth.\nCombining the plus + and period . characters can be particularly powerful in regular expressions, instructing the program to find any amount of any characters within your search. A search for\nd.+g\nfor example, might return \u0026ldquo;dried fruits are g\u0026rdquo;, because the string begins with \u0026ldquo;d\u0026rdquo; and ends with \u0026ldquo;g\u0026rdquo;, and has various characters in the middle. Searching for simply .+ will yield query results that are entire lines of text, because you are searching for any character, and any amount of them.\nParentheses in regular expressions are also very useful when replacing text. The text within a regular expression forms what\u0026rsquo;s called a group, and the software you use to search remembers which groups you queried in order of their appearance. For example, if you search for\n(dogs)( and )(cats)\nwhich would find all instances of \u0026ldquo;dogs and cats\u0026rdquo; in your document, your program would remember \u0026ldquo;dogs\u0026rdquo; is group 1, \u0026ldquo;and\u0026rdquo; is group 2, and \u0026ldquo;cats\u0026rdquo; is group 3. Sublime Text remembers them as \\1, \\2, and \\3 for each group respectively.\nIf you wanted to switch the order of \u0026ldquo;dogs\u0026rdquo; and \u0026ldquo;cats\u0026rdquo; every time the phrase \u0026ldquo;dogs and cats\u0026rdquo; appeared in your document, you would type\n(dogs)( and )(cats)\nin the \u0026lsquo;find\u0026rsquo; box, and\n\\3\\2\\1\nin the \u0026lsquo;replace\u0026rsquo; box. That would replace the entire string with group 3 (\u0026ldquo;cats\u0026rdquo;) in the first spot, group 2 (\u0026rdquo; and \u0026ldquo;) in the second spot, and group 1 (\u0026ldquo;dogs\u0026rdquo;) in the last spot, thus changing the result to \u0026ldquo;cats and dogs\u0026rdquo;.\nThe vocabulary of regular expressions is pretty large, but there are many cheat sheets for regex online.\nLetters of the Republic of Texas The correspondence of the Republic of Texas, and independent state from 1835 to 1846 was collated into a single volume and published with a helpful index in 1911. It was scanned and OCR\u0026rsquo;d by Google, and is now available as a text file from the Internet Archive. You can see the OCR\u0026rsquo;d text at archive.org. We are going to use it to practice our regex skills because it is an example of a historical network we might want to analyze later with network analysis. We are going to grab the index from that file, and transform it using regex.\nEntries in the index look like this:\nSam Houston to A. B. Roman, September 12, 1842 101 Sam Houston to A. B. Roman, October 29, 1842 101 Correspondence for 1843-1846 — Isaac Van Zandt to Anson Jones, January 11, 1843 103 We are going to use regex to tidy this up, delete some parts, and end up with data that looks like this:\nSam Houston, A. B. Roman, September 12 1842 Sam Houston, A. B. Roman, October 29 1842 Isaac Van Zandt, Anson Jones, January 11 1843 The change doesn\u0026rsquo;t look like much, and you might think to yourself, \u0026lsquo;hey, I could just do that by hand\u0026rsquo;. You could but it\u0026rsquo;d take you ages, and if you made a mistake somewhere, are you sure you could do this consistently, for a couple of hours at a time? Probably not. Your time is better spent figuring out the search and replace patterns, and then setting your machine loose to implement it.\n  We will use the curl command at the command prompt to grab the file; this is a related command to wget whom you\u0026rsquo;ve already met. Mac users should already have this installed; Windows users can open up Anaconda PowerShell and type conda install -c anaconda curl to get it.\n  At the command line, type the following curl command:\n  $ curl http://archive.org/stream/diplomaticcorre33statgoog/diplomaticcorre33statgoog_djvu.txt \u0026gt; texas.txt\nThe curl command downloads the txt file and the the \u0026gt; pushes the result of the command to a file called texas.txt.\n Open texas.txt in Sublime Text, and open the Find menu and hit the Replace option; this opens the find and replace panel at the bottom of your window. Make sure to press the .* button in that panel to turn on regular expression search.\n  Delete everything in this file that isn\u0026rsquo;t the table of letters. The table starts with ‘Sam Houston to J. Pinckney Henderson, December 31, 1836 51’ and ends with ‘Wm. Henry Daingerfield to Ebenezer Allen, February 2, 1846 1582’. Your file will now have approximately 2000 lines in it.\n  First thing we\u0026rsquo;re going to do is identify any lines that indicate correspondence. We\u0026rsquo;re going to look for the word \u0026lsquo;to\u0026rsquo;. In fact, we don\u0026rsquo;t just want to find \u0026ldquo;to\u0026rdquo;, but the entire line that contains it. We assume that every line that contains the word \u0026ldquo;to\u0026rdquo; in full is a line that has relevant letter information, and every line that does not is one we do not need.\n  You learned earlier that the pattern .+ returns any amount of text, no matter what it says, and that \\b indicates a word boundary. Thus, the pattern we want looks like this .+\\bto\\b.+. Don\u0026rsquo;t search yet.\nWe want to mark these lines off as special, so let\u0026rsquo;s add a tilde ~ before each of the lines that look like letters. This involves the find-and-replace function, and a query identical to the one before, but with parentheses around it, so it looks like the following\n(.+\u0026lt;to\u0026gt;)\nand the entire line is placed within a parenthetical group. Since this the first group in our search expression, we can replace that group with \\1 and put the tilde in front of it like so: ~\\1.\nDo this\nsearch for: (.+\\\u0026lt;to\\\u0026gt;)\nreplace with: ~\\1\nAfter running the find-and-replace, you should note your document now has most of the lines with tildes in front of it, and a few which do not. The next step is to remove all the lines that do not include a tilde. The search string to find all lines which don\u0026rsquo;t begin with tildes is \\n[^~].+  Within a set of square brackets [] the carrot ^ means search for anything that isn\u0026rsquo;t within these brackets (in this case, the tilde ~). The .+ as before means search for every remaining character in the line as well. All together, the query returns any full line which does not begin with a tilde; that is, the lines we did not mark as looking like letters. We search for the pattern, and leave the replace blank; this will delete the lines that do not begin with a tilde.\nDo this\nsearch for: \\n[^~].+\nreplace with:\nTo turn this text file into a csv suitable for network analysis, we\u0026rsquo;ll want to separate it out into one column for Sender, one for Recipient, and one for Date, each separated by a single comma. Notice that most lines have extraneous page numbers attached to them; we can get rid of those with regular expressions. There\u0026rsquo;s also usually a comma separating the month-date and the year, which we\u0026rsquo;ll get rid of as well. In the end, the first line should go from looking like the following:  ~Sam Houston to J. Pinckney Henderson, December 31, 1836 51\nto looking like the following:\nSam Houston, J. Pinckney Henderson, December 31 1836\nRead through before you do anything. You will start by removing the page number after the year and the comma between the year and the month-date. To do this, first locate the year on each line by using the regex:\n[0-9]{4}\nWe can find any digit between 0 and 9 by searching for [0-9], and {4} will find four of them together. Now extend that search out by appending .+ to the end of the query; as seen before, it will capture the entire rest of the line. The following query:\n`[0-9]{4}.+`  will return, for example, \u0026ldquo;1836 51\u0026rdquo;, \u0026ldquo;1839 52\u0026rdquo;, and \u0026ldquo;1839 53\u0026rdquo; from the first three lines of the text. We also want to capture the comma preceding the year, so add a comma and a space before the query, resulting in the following:\n `, [0-9]{4}.+`  which will return \u0026ldquo;, 1836 51\u0026rdquo;, \u0026ldquo;, 1839 52\u0026rdquo;, etc.\nThe next step is making the parenthetical groups which will be used to remove parts of the text with find-and-replace. In this case, we want to remove the comma and everything after \u0026lsquo;year\u0026rsquo;, but not the year or the space before it. Thus our query will look like the following:\n`(,)( [0-9]{4})(.+)`  with the comma as the first group \\1, the space and the year as the second \\2, and the rest of the line as the third \\3. Given that all we care about retaining is the second group (we want to keep the year, but not the comma or the page number), what will the replace look like? You only want to keep the second group.\n  It\u0026#39;ll look like this  search: (,)( [0-9]{4})(.+)\nreplace: \\2\nNow go ahead and do that.\n   Find the tildes that we used to mark off our text of interest, and replace them with nothing to delete them.\n  Finally, to separate the Sender and Receiver by a comma, we find all instances of the word \u0026ldquo;to\u0026rdquo; and replace it with a comma. Although we used \\b and \\b to denote the beginning and end of a word earlier in the lesson, we don\u0026rsquo;t exactly do that here. We include the space preceding \u0026ldquo;to\u0026rdquo; in the regular expression, as well as the  \\b to denote the word ending. Once we find instances of the word and the space preceding it, to\\b we replace it with a comma ,.\n  Do this\nsearch: (\\b to \\b)\nreplace: ,\n You now have a document that contains senders, recipients, and the date in three columns separated by commas. Well done! You\u0026rsquo;ll need to insert a line right at line 1 though to make this clear: at the top of the file, add a new line that simply reads \u0026ldquo;Sender, Recipient, Date\u0026rdquo;.\n  You may notice that some lines still do not fit our criteria. Line 22, for example, reads \u0026ldquo;Abner S. Lipscomb, James Hamilton and A. T. Bumley, AugUHt 15, \u0026ldquo;. It has an incomplete date; we don\u0026rsquo;t need to worry about these for our purposes.\n  More worrisome are lines, like 61 \u0026ldquo;Copy and summary of instructions United States Department of State, \u0026quot; which include none of the information we want. We can get rid of these lines later in a spreadsheet.\nThe only non-standard lines we need to worry about with regular expressions are the ones with more than 2 commas, like line 178, \u0026ldquo;A. J. Donelson, Secretary of State [Allen,. arf interim], December 10 1844\u0026rdquo;. Notice that our second column, the name of the Recipient, has a comma inside of it. If you were to import this directly into a spreadsheet, you would get four columns, one for Sender, two for Recipient, and one for date, which would break any analysis you would then like to run. Unfortunately these lines need to be fixed by hand, but happily regular expressions make finding them easy. The following query:\n.+,.+,.+,\nwill show you every line with more than 2 commas, because it finds any line that has any set of characters, then a comma, then any other set, then another comma, and so forth. You can just \u0026lsquo;find all\u0026rsquo; and then Sublime will show you the lines to fix manually.\nPhew That was a lot of work. Save your file with a new name: correspondence.csv. You now have a document that can be visualized as a network and analyzed as such.\n","description":"Basic Tools","id":7,"section":"week","tags":null,"title":"REGEX","uri":"https://craftingdh.netlify.com/week/3/regex/"},{"content":"voyant\n","description":"Of Macroscopes and Microscopes","id":8,"section":"week","tags":null,"title":"Voyant","uri":"https://craftingdh.netlify.com/week/4/voyant/"},{"content":" audacity sonification  ","description":"Telling the Compelling Story","id":9,"section":"week","tags":null,"title":"Sound","uri":"https://craftingdh.netlify.com/week/5/sound/"},{"content":"   While watching this video, turn on the closed captions.\nCreate an account at hypothes.is:\nGet the Chrome app or the Firefox bookmarklet:\nMake sure you\u0026rsquo;re logged in:\nThen join our HIST3814o reading group. If you happen to be reading something, and see an existing annotation that interests you, hit the \u0026lsquo;reply\u0026rsquo; button on the annotation to start a conversation! Sometimes, the person to whom you\u0026rsquo;re replying might be a previous year\u0026rsquo;s student, but that\u0026rsquo;s ok; they might enter into conversation with you. Sometimes, it might be a person who isn\u0026rsquo;t a Carleton student but is following along with the course. That\u0026rsquo;s ok too. Be respectful!\nThere is a student guide to Hypothes.is behind this link. Read that for the full information how using Hypothesis.\n","description":"instructions","id":10,"section":"week","tags":null,"title":"Setting up your Hypothesis","uri":"https://craftingdh.netlify.com/week/1/hypothesis/"},{"content":"The following combines elements of Ian Milligan\u0026rsquo;s tutorial at The Programming Historian, as well as Kellen Kurschinski\u0026rsquo;s.\nIntroduction Wget is a program for downloading materials from the web. It is extremely powerful: if we do it wrong we can look like an attacker, or worse, download the entire internet! We use this program on the command line. We will cover some of the basics, and then we will create a little program that uses wget to download materials from Library and Archives Canada.\nIn what follows, push yourself until you get stuck. I\u0026rsquo;m not interested in how far you get, but rather in how you document what you are able to do, how you look for help, how you reach out to others - or how you help others over the bumps. I know also that you all have lots of other claims on your time. Reading through all of this and making notes on what you do/don\u0026rsquo;t understand is fine too.\r Installation Mac Users\nYou will need a tool called \u0026lsquo;homebrew\u0026rsquo; to obtain wget. Homebrew is a \u0026lsquo;package manager\u0026rsquo;, or a utility that retrieves software from a single, \u0026lsquo;official\u0026rsquo; (as it were) source. To install home brew, copy the command below and enter it at your terminal:\n$ /usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot; Then, make sure everything is set up correctly with brew, enter: $ brew doctor\nAssuming all has gone well, get wget: $ brew install wget\nThen test that it installed: $ wget If it has installed, you\u0026rsquo;ll get the message -\u0026gt; missing URL.. If it hasn\u0026rsquo;t you\u0026rsquo;ll see -\u0026gt; command not found.\nWindows\nGo to this website and right-click, \u0026lsquo;save target as\u0026rsquo; the file for the 32-bit version 1.20.3 EXE file.\nMove this file out of your Downloads folder into your C:\\Windows directory. That way, when you type wget at the command prompt, Windows will find it.\nBasic Usage Wget expects you to enter the URL to a webpage or some other online file. How do websites organize things? Milligan writes:\n Let’s take an example dataset. Say you wanted to download all of the papers hosted on the website ActiveHistory.ca. They are all located at: http://activehistory.ca/papers/; in the sense that they are all contained within the /papers/ directory: for example, the 9th paper published on the website is http://activehistory.ca/papers/historypaper-9/. Think of this structure in the same way as directories on your own computer: if you have a folder labeled /History/, it likely contains several files within it. The same structure holds true for websites, and we are using this logic to tell our computer what files we want to download.\n So let\u0026rsquo;s try to do that. At the command prompt or terminal, let\u0026rsquo;s make a new directory to do our work in:\n$ mkdir wget-activehistory $ cd wget-activehistory and let\u0026rsquo;s grab the index page from the papers directory:\n$ wget http://activehistory.ca/papers/\nta da! Look around in that directory, see what got downloaded.\nBut that was only one file. We\u0026rsquo;re going to add some more flags to the command to tell wget to recursively follow links (using the -r flag) in that folder but to only follow the links that lead to destinations within the folder (using the -np meaning \u0026lsquo;no parent\u0026rsquo;). Otherwise we could end up grabbing materials five steps away from this site! (If we did want materials outside of where we started, we\u0026rsquo;d use the -l flag, \u0026lsquo;links\u0026rsquo;). Finally, we don\u0026rsquo;t want to be attacking the site demanding gimme gimme gimme materials. We use the -w flag to wait between requests, and to --limit-rate=20k to narrow the bandwidth our request requires.\n -r recursive -np no-parent -l links beyond domain we started in -w wait time between requests to the server --limit-rate= limit the bandwidth for our request (which necessarily slows down how long it\u0026rsquo;ll take to perform the request)  Altogether, our command now looks like this:\n$ wget -r -np -w 2 --limit-rate=20k http://activehistory.ca/papers/\nGive that a try!\nUsing wget with a list of urls Let us assume that you were very interested in the history of health care in this country. Through the Library and Archives Canada search interface, you\u0026rsquo;ve found the Laura A. Gamble fonds, a nurse originally from Wakefield Quebec (just north of Ottawa).\nYou click through, and find the first image of her diary; if you right-click on that image and select view image you find that the file path to the image: http://data2.archives.ca/e/e001/e000000422.jpg.\nNow, if Library and Archives Canada had an API for their collection (an \u0026lsquo;application programming interface\u0026rsquo;, or a set of commands that we could use on our end to deduce the locations of the information we want), we could just figure out the urls for each image of the diary in that fonds. But they don\u0026rsquo;t. Turns out, the urls we want run from \u0026hellip;422 to \u0026hellip;425 (but try entering other numbers at the end of that URL: you will retrieve who-knows-what!):\n In sublime text, create a new file and paste these urls into it; save the file as urls.txt  http://data2.archives.ca/e/e001/e000000422.jpg http://data2.archives.ca/e/e001/e000000423.jpg http://data2.archives.ca/e/e001/e000000424.jpg http://data2.archives.ca/e/e001/e000000425.jpg Now, we know that we can pass an indivual url to wget and wget will retrieve it; we can also pass urls.txt to wget, and wget will grab every file in turn!\nTry this at the terminal/command prompt:  $ wget -i urls.txt -r --no-parent -nd -w 2 --limit-rate=100k\n(google for wget options)\nUsing python to generate a list of urls Now, let\u0026rsquo;s try something a bit more complex. It\u0026rsquo;s one thing to manually copy and paste urls into a file, but what if we want a lot of files? You could just set wget to crawl directories, but that can make you look like an attacker, it can clutter your own machine with files you don\u0026rsquo;t want, and it can mess with your bandwidth and data caps. Sometimes though we can suss out the naming pattern for files, and so write a small program that will automatically write out all of the urls for us.\nConsider the 14th Canadian General Hospital war diaries. The URLs of this diary go from http://data2.archives.ca/e/e061/e001518029.jpg to http://data2.archives.ca/e/e061/e001518109.jpg. That\u0026rsquo;s 80 pages.\n make a new directory for our work - at the command prompt or terminal, $ mkdir war-diaries Create a new file in Sublime Text. I\u0026rsquo;ll give you the script to paste in there, and then I\u0026rsquo;ll explain what it\u0026rsquo;s doing.  1 2 3 4 5 6  urls = \u0026#39;\u0026#39;; f=open(\u0026#39;urls.txt\u0026#39;,\u0026#39;w\u0026#39;) for x in range(8029, 8110): urls = \u0026#39;http://data2.collectionscanada.ca/e/e061/e00151%d.jpg\\n\u0026#39; % (x) f.write(urls) f.close   First, we\u0026rsquo;re creating an empty \u0026lsquo;bin\u0026rsquo; or varialbe called \u0026lsquo;urls\u0026rsquo;. Then, we create a variable called f for file, and tell it to open a new text file called \u0026lsquo;urls\u0026rsquo;. Then we set up a loop with the for command that will iterate over the 80 values from 8029 to 8110. The next line contains our pattern, the full url right up until e0151. The last little bit, the %d takes the number of the current iteration and pastes that in. The \\n means \u0026lsquo;new line\u0026rsquo; so that when we iterate through this again, we\u0026rsquo;ve moved the cursor down one line. Then with f.write(urls) we put the pattern into the file. Once we\u0026rsquo;ve finished - we\u0026rsquo;ve gotten all the way to 8110 - the loop is done, we close the file, and the script stops.\n Save this file as urls.py in your directory war-diaries. The .py reminds us that to run this file we\u0026rsquo;ll need to invoke it with python.\n  At the command prompt / terminal (windows: ananconda powershell remember!) make sure you are in your war-diaries directory with pwd to see where you are, and cd as appropriate to get to where you need to be.\n  Make sure the file is there: type ls or dir as appropriate and make sure you see the file. Let\u0026rsquo;s run this file: $ python urls.py. After a brief pause, you should just be presented with a new prompt, as if nothing has happened: but check your directory (ls or dir) and you\u0026rsquo;ll see a new file: urls.txt. You can open this with Sublime Text to see what\u0026rsquo;s inside.\n  Now that you\u0026rsquo;ve got the urls, use wget as you did for Laura Gamble\u0026rsquo;s diary (it\u0026rsquo;s the exact same command). It might go rather slowly, but keep an eye on your file explorer or finder. What have you got in your directory now?\n  Be a good digital citizen Always use the wait and limit-rate flags so that you do not overwhelm the server (the computer at the address of your url) with your requests. You can get yourself into trouble if you don\u0026rsquo;t. Make sure you understand the ideas around recursively following links, link depth, and \u0026lsquo;no-parents.\u0026rsquo; Read the original tutorials by Ian Milligan at The Programming Historian, and Kellen Kurschinski for more details.\n","description":"instructions","id":11,"section":"week","tags":null,"title":"Wget","uri":"https://craftingdh.netlify.com/week/2/wget/"},{"content":"Open refine\n","description":"Basic Tools","id":12,"section":"week","tags":null,"title":"Open Refine","uri":"https://craftingdh.netlify.com/week/3/open-refine/"},{"content":"antconc\n","description":"Of Macroscopes and Microscopes","id":13,"section":"week","tags":null,"title":"AntConc","uri":"https://craftingdh.netlify.com/week/4/antconc/"},{"content":"Goals for this week  experience something of the cycle of digital history by trying some exploratory analysis with the tools/approaches you\u0026rsquo;ve learned  Listen Read Do Remember back in week one, how I had you explore that twitter thread by Amalia Skarlatou Levi? This week, you\u0026rsquo;ll be selecting one of those resources she shared (or, if none strike your fancy, something from the resources gathered here) to do some exploratory digital history.\nYou will use at least three appropriate techniques from weeks 1 to 4 to identify and surface some interesting historical observations from those sources, and you will imagine the possible directions such research might take.\nYou will share your results using an appropriate technique you encountered in week 5. Other possibilities are ok too; just check with Dr. Graham first. Remember, you don\u0026rsquo;t have a lot of time, so keep your ambitions in check: the perfect is the enemy of the good.\n When/if you run into trouble, take screenshots (google how to do that for your particular machine) and these can be uploaded into your repository as well. Indeed, you should also keep track of any files you create as part of your weekly work in your repo: these are evidence!  With tech work, if it doesn\u0026rsquo;t come together in about 30 minutes, it won\u0026rsquo;t come in an hour. So take a break. Close the laptop. Call somebody up for help. Find another pair of eyes to look at the problem. I don\u0026rsquo;t want to hear that you labored heroically for 2 hours to do something. Jump into our social space and ask for advice. Remember: it\u0026rsquo;s not how many you do, it\u0026rsquo;s that you pushed yourself that matters.\r Record and Reflect   As you have been doing, make another notes.md entry and put it in your repo for week 6.\n  In your journal.md for this week, think about this. Digital history is a process of encountering a body of information that suggests a question or two to you and then cycling back to that body of information to better understand the question (we haven\u0026rsquo;t even got to an answer yet!). In so doing, you\u0026rsquo;ll discover that the information is messy, or in the not-quite-right format. 80% of our time, as digital historians, is just getting things into shape for us to begin our exploration!\n  Submit work You can submit the link to your work on this form\n","description":"Bringing it all Together","id":14,"section":"week","tags":null,"title":"Instructions: June 8","uri":"https://craftingdh.netlify.com/week/6/instructions/"},{"content":" storymap leaflet webmapping != GIS, pointers to QGIS  ","description":"Telling the Compelling Story","id":15,"section":"week","tags":null,"title":"Mapping","uri":"https://craftingdh.netlify.com/week/5/mapping/"},{"content":"Sometimes, a website will have what is called an Application Programming Interface or API. In essence, this lets a program on your computer talk to the computer serving the website you\u0026rsquo;re interested in, such that the website gives you the data that you\u0026rsquo;re looking for.\nAn API is just a way of opening up a program so that another program can interact with it. That is, instead of an interface meant for a human to interact with the machine, there’s an API to allow some other machine to interact with this one. If you’ve ever downloaded an app on your phone that allowed you to interact with Instagram (but wasn’t Instagram itself), that interaction was through Instagram’s API, for instance.\nA good API will also have documentation explaining what or how to make calls to it to get the information you want. That is, instead of you punching in the search terms on a search page, and copying and pasting the results, you frame a request as a URL. More or less. The results often come back to you in a text format where data is organized according to keys and values (JSON). Sometimes it\u0026rsquo;s just a table of data using commas to separate each field for each row (.csv file). JSON looks like the following:\nIn what follows, push yourself until you get stuck. I\u0026rsquo;m not interested in how far you get, but rather in how you document what you are able to do, how you look for help, how you reach out to others - or how you help others over the bumps. I know also that you all have lots of other claims on your time. Reading through all of this and making notes on what you do/don\u0026rsquo;t understand is fine too.\r Getting material out of an API Each API has its own idiosyncracies, but we can always look at the documentation and figure out how to form our requests so that our programs grab the data we\u0026rsquo;re after. The Chronicling America website from the Library of Congress has digitized American newspapers from 1789 to 1963. While the site has a fine search interface, we\u0026rsquo;ll use the API to grab every article that mentions the word \u0026lsquo;archeology\u0026rsquo; (sic).\nFirst of all, go to the Cronicling America site and search in the text box for archeology. Notice how the url changes when it brings back the results:\nhttps://chroniclingamerica.loc.gov/search/pages/results/?state=\u0026amp;date1=1789\u0026amp;date2=1963\u0026amp;proxtext=archeology\u0026amp;x=0\u0026amp;y=0\u0026amp;dateFilterType=yearRange\u0026amp;rows=20\u0026amp;searchType=basic\nThere\u0026rsquo;s a lot of stuff in there - amongst other things, we can see a setting for state, for date1 and date2, our search term appears as the value for a setting called proxtext. This is the API in action.\nLet\u0026rsquo;s build.\n Open a new file in Sublime Text. We\u0026rsquo;ll first put a bit of metadata in our file, for the programme we\u0026rsquo;re going to write:  1 2 3 4 5 6 7 8 9 10  #!/usr/bin/env python \u0026#34;\u0026#34;\u0026#34; a script for getting materials from the Chronicling America website \u0026#34;\u0026#34;\u0026#34; # Make these modules available import requests import json __author__ = \u0026#34;your-name\u0026#34;   The first bit tells us this is a python file. The next bit tells us what the file is for. The import tells python that we\u0026rsquo;ll need a module called requests which lets us grab materials from the web, and json which helps us deal with json formatted data. The final bit says who wrote the script.\nNow we\u0026rsquo;re going to define some variables to hold the bit of the search url up to where the ? occurs - everything after the question mark are the parameters we want the API to search. We create the api_searh_url, define the parameter we want to search for, and define how we want the results returned to us. Add the following to your script:  1 2 3 4 5 6 7 8 9 10  # Create a variable called \u0026#39;api_search_url\u0026#39; and give it a value api_search_url = \u0026#39;https://chroniclingamerica.loc.gov/search/pages/results/\u0026#39; # This creates a dictionary called \u0026#39;params\u0026#39; and sets values for the API\u0026#39;s mandatory parameters params = { \u0026#39;proxtext\u0026#39;: \u0026#39;archeology\u0026#39; # Search for this keyword  } # This adds a value for \u0026#39;encoding\u0026#39; to our dictionary params[\u0026#39;format\u0026#39;] = \u0026#39;json\u0026#39;   Now we\u0026rsquo;ll send the request to the server, and we\u0026rsquo;ll add a bit of error checking so that if something is wrong, we\u0026rsquo;ll get some indication of why that is. Add this to your script:  1 2 3 4 5 6 7 8 9 10 11 12 13  # This sends our request to the API and stores the result in a variable called \u0026#39;response\u0026#39; response = requests.get(api_search_url, params=params) # This shows us the url that\u0026#39;s sent to the API print(\u0026#39;Here\\\u0026#39;s the formatted url that gets sent to the ChronAmerca API:\\n{}\\n\u0026#39;.format(response.url)) # This checks the status code of the response to make sure there were no errors if response.status_code == requests.codes.ok: print(\u0026#39;All ok\u0026#39;) elif response.status_code == 403: print(\u0026#39;There was an authentication error. Did you paste your API above?\u0026#39;) else: print(\u0026#39;There was a problem. Error code: {}\u0026#39;.format(response.status_code))   Now let\u0026rsquo;s get the results, and put them into a variable called \u0026lsquo;data\u0026rsquo;. Then we\u0026rsquo;ll print the results to the terminal, and finish by also writing the results to a file.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # Get the API\u0026#39;s JSON results and make them available as a Python variable called \u0026#39;data\u0026#39; data = response.json() # Let\u0026#39;s prettify the raw JSON data and then display it. # We\u0026#39;re using the Pygments library to add some colour to the output, so we need to import it from pygments import highlight, lexers, formatters # This uses Python\u0026#39;s JSON module to output the results as nicely indented text formatted_data = json.dumps(data, indent=2) # This colours the text highlighted_data = highlight(formatted_data, lexers.JsonLexer(), formatters.TerminalFormatter()) # And now display the results print(highlighted_data) # dump json to file with open(\u0026#39;data.json\u0026#39;, \u0026#39;w\u0026#39;) as outfile: json.dump(data, outfile)   Save your file as ca.py. Open a terminal/command prompt (remember Windows folks: anaconda powershell!) in the folder where you saved this file, and run it with:\n$ python ca.py\nYour terminal will look like it\u0026rsquo;s frozen for a few moments; that\u0026rsquo;s because your computer is reaching out to the Chronicling America website, making its request, and pulling down the results. But in seconds, you\u0026rsquo;ll have a data.json file with loads of data - 9021 articles in fact!\nCongratulations, you now have a program that you wrote that you can use to obtain all sorts of historical information.\nYour complete file will look like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  #!/usr/bin/env python \u0026#34;\u0026#34;\u0026#34; a script for getting materials from the Chronicling America website \u0026#34;\u0026#34;\u0026#34; # Make these modules available import requests import json __author__ = \u0026#34;your-name\u0026#34; # Create a variable called \u0026#39;api_search_url\u0026#39; and give it a value api_search_url = \u0026#39;https://chroniclingamerica.loc.gov/search/pages/results/\u0026#39; # This creates a dictionary called \u0026#39;params\u0026#39; and sets values for the API\u0026#39;s mandatory parameters params = { \u0026#39;proxtext\u0026#39;: \u0026#39;archeology\u0026#39; # Search for this keyword } # This adds a value for \u0026#39;encoding\u0026#39; to our dictionary params[\u0026#39;format\u0026#39;] = \u0026#39;json\u0026#39; # This sends our request to the API and stores the result in a variable called \u0026#39;response\u0026#39; response = requests.get(api_search_url, params=params) # This shows us the url that\u0026#39;s sent to the API print(\u0026#39;Here\\\u0026#39;s the formatted url that gets sent to the ChronAmerca API:\\n{}\\n\u0026#39;.format(response.url)) # This checks the status code of the response to make sure there were no errors if response.status_code == requests.codes.ok: print(\u0026#39;All ok\u0026#39;) elif response.status_code == 403: print(\u0026#39;There was an authentication error. Did you paste your API above?\u0026#39;) else: print(\u0026#39;There was a problem. Error code: {}\u0026#39;.format(response.status_code)) # Get the API\u0026#39;s JSON results and make them available as a Python variable called \u0026#39;data\u0026#39; data = response.json() # Let\u0026#39;s prettify the raw JSON data and then display it. # We\u0026#39;re using the Pygments library to add some colour to the output, so we need to import it from pygments import highlight, lexers, formatters # This uses Python\u0026#39;s JSON module to output the results as nicely indented text formatted_data = json.dumps(data, indent=2) # This colours the text highlighted_data = highlight(formatted_data, lexers.JsonLexer(), formatters.TerminalFormatter()) # And now display the results print(highlighted_data) # dump json to file with open(\u0026#39;data.json\u0026#39;, \u0026#39;w\u0026#39;) as outfile: json.dump(data, outfile)   Some other APIs You can modify this code to extract information from other APIs, but it takes a bit of tinkering. In essence, you need to study the website to see how they form the API, and then change up lines 13, 17 and 21 accordingly. You can see this in action for instance here, with regard to the Metropolitan Museum of Art or here, with regard to the Smithsonian.\nBut\u0026hellip; it\u0026rsquo;s in json format? JSON is handy for lots of computational tasks, but for you as a beginning digital historian, you might want to have the data as a table. There are a couple of options here. The easiest right now - and there\u0026rsquo;s no shame in doing this - is to use an online converter. This site: json-csv.com lets you convert your json file to csv or Excel spreadsheet, and even transfer it over to a google doc. Give that a shot right now; the text of the articles by the way is in the field \u0026lsquo;ocr_eng\u0026rsquo; which tells us that the text was originally transcribed from the images using object character recognition - so there will be errors and weird glitches in the text. Fortunately, there\u0026rsquo;s also a URL with the direct link to the original document, so you can check things for yourself.\nGLAM Workbench \u0026lsquo;GLAM\u0026rsquo; stands for \u0026lsquo;galleries, libraries, archives, and museums\u0026rsquo;. The GLAM Workbench is by Tim Sherratt, a digital historian in Australia. I would strongly recommend that you explore and give the Workbench a whirl if you are at all interested in the kinds of work that you might be able to do when you are computationally able to treat collections as data. For a glimpse as to what that might mean, check out this presentation.\n","description":"instructions","id":16,"section":"week","tags":null,"title":"APIs","uri":"https://craftingdh.netlify.com/week/2/apis/"},{"content":"Zotero is a piece of software for managing your research. When it is installed, it can extract metadata from websites or pdfs (when these have metadata) and store the information in your very own library. Zotero can be connected to Word or Google Docs so that when it is time to insert a reference, you can select the reference from your library - and then get the machine to automatically format/update your bibliography against whatever citation style you use.\nA tutorial on how to get, how to install, and how to use Zotero to keep track of what you read. Right-click and open in a new window; this tutorial from the UCLA Library will also show you how to use Zotero effectively.\nYou can download Zotero here. Note that you have to also install \u0026lsquo;connectors\u0026rsquo; for your browser.\nThe installation instructions for Zotero are here.\n","description":"instructions","id":17,"section":"week","tags":null,"title":"Setting up your Zotero","uri":"https://craftingdh.netlify.com/week/1/zotero/"},{"content":"Network stuff\n","description":"Basic Tools","id":18,"section":"week","tags":null,"title":"Networks","uri":"https://craftingdh.netlify.com/week/3/networks/"},{"content":"use the new stuff? throw some tf-idf in here\n","description":"Of Macroscopes and Microscopes","id":19,"section":"week","tags":null,"title":"Topic Models","uri":"https://craftingdh.netlify.com/week/4/topic-models/"},{"content":" academic posters infographics  colour theory, layout, stuff from macroscope re scott chapter\n","description":"Telling the Compelling Story","id":20,"section":"week","tags":null,"title":"Infographics","uri":"https://craftingdh.netlify.com/week/5/infographics/"},{"content":"What is Discord? You can download Discord here or you can use it in a broswer.\nYou will receive an invitation email in your Carleton account. It expires after one day, so do join once you get it. It will ask to verify your email; check your spam folder.\nOnce you\u0026rsquo;re in, there\u0026rsquo;s a welcome message with a reaction emoji at the end - click on the thumbs up to confirm that you\u0026rsquo;ve read the message. This will unlock the various channels in the server, including voice and screensharing.\n(Alex is a student who works for me on the bone trade project if you were wondering.)\nYou can customize your profile by clicking on the cogwheel icon at the bottom of the navigation:\nand you can customize how you\u0026rsquo;d like to use voice and video:\nThere\u0026rsquo;s a channel for each week\u0026rsquo;s materials, a channel for general history or Carleton chat, and a social channel just for shooting the breeze. If you want to chat or stream your machine (eg to show us what you\u0026rsquo;re trying to do and how it\u0026rsquo;s not working) just click on one of the side-chats - make sure you\u0026rsquo;re unmuted! Dr. Graham also has a private office for voide and video and you can ask him directly to speak there.\nWhat all the buttons do help file\nDiscord has accessibility features, more details here\n","description":"instructions","id":21,"section":"week","tags":null,"title":"Getting started with Discord","uri":"https://craftingdh.netlify.com/week/1/discord/"},{"content":"Object Character Recognition is a technique that looks at the pattern of light and dark pixels in an image and matches them against the alphabet. The technique was developed against clean type-written pages where the letters were crisply made. On historical documents, things can get pretty hit-and-miss. When we searched the Chronicling America website, we were actually searching the OCR\u0026rsquo;d text that was embedded in each of those pdfs (if you can select text in a pdf, it has a hidden text layer on top of the image. If you can\u0026rsquo;t, it\u0026rsquo;s just an image). We probably missed a lot of information because we searched for \u0026lsquo;archeology\u0026rsquo; but it\u0026rsquo;s entirely possible the word got transcribed as \u0026lsquo;arc50log\u0026rsquo; or other similar mismashes. Just because you searched, didn\u0026rsquo;t mean you found what was there!\nIn this walk through, we\u0026rsquo;re going to use the R language to run some images through the OCR process. I am not teaching you R, but rather, giving you two recipes that you can use.\nIn what follows, push yourself until you get stuck. I\u0026rsquo;m not interested in how far you get, but rather in how you document what you are able to do, how you look for help, how you reach out to others - or how you help others over the bumps. I know also that you all have lots of other claims on your time. Reading through all of this and making notes on what you do/don\u0026rsquo;t understand is fine too.\r One file at a time  Open Anaconda Navigator, and hit the \u0026lsquo;Install R Studio\u0026rsquo; button.\n Launch R Studio\n RStudio has within it a console, a script editor, a file explorer, and lots of other features. Click on the new button to make a new R Script.\n  We are going to OCR this image, from the 14th Canadian General Hospital war diaries:\n Right-click on that image, \u0026lsquo;save-as\u0026rsquo;, and save it somewhere sensible on your computer.\n  Using the file explorer in R Studio, navigate to where you saved that file.\n  Make that folder your \u0026lsquo;working directory\u0026rsquo;; you can do this by clicking on the \u0026lsquo;More\u0026rsquo; button beside the cogwheel. When you do this, the actual R command that achieves this will also copy into the console. R Studio now knows where to look for files, and where to save them.\n  In the script window, paste the following lines:  1 2 3  # install only the first time install.packages(\u0026#39;magick\u0026#39;) install.packages(\u0026#39;tesseract\u0026#39;)   We\u0026rsquo;ll only run these lines once, because once we\u0026rsquo;ve installed these bits of lego, we won\u0026rsquo;t have to install them again; they\u0026rsquo;ll always be available for use. Highlight all of them with your cursor, and hit the \u0026lsquo;run\u0026rsquo; button at the top of the window. Running the lines passes them to the console where they are executed; you\u0026rsquo;ll see a bunch of information scroll by as they install. Then, when it\u0026rsquo;s finished, you\u0026rsquo;ll see the \u0026gt; prompt again.\nAdd to your script these lines:  1 2 3 4  # tell R which packages you need library(magick) library(magrittr) library(tesseract)   And run them. Down in the console, nothing much should happen, but you should get the \u0026gt; again.\nAnd now let\u0026rsquo;s ocr some text. Add these lines to your script:  1 2 3 4 5 6 7 8 9 10 11 12 13  # now let\u0026#39;s create a variable called \u0026#39;text\u0026#39; # and read the image into it # and we\u0026#39;ll modify the image to give us # the best chance of reading the text # the final line, image_ocr() does the text extraction # remember to set your working directory to whatever folder # contains the stuff you want to work on. text \u0026lt;- image_read(\u0026#34;e001518030.jpg\u0026#34;) %\u0026gt;% image_resize(\u0026#34;2000\u0026#34;) %\u0026gt;% image_convert(colorspace = \u0026#39;gray\u0026#39;) %\u0026gt;% image_trim() %\u0026gt;% image_ocr()   If you put your cursor at the \u0026lsquo;t\u0026rsquo; in \u0026lsquo;text\u0026rsquo;, and hit \u0026lsquo;run\u0026rsquo;, R Studio knows that all of these lines are joined by the %\u0026gt;% function, or pipe, and so will run everything in order to the final command, image_ocr().\nYou know it ran, because it passed the commands to the console, and you got the command prompt back.\nFinally, let\u0026rsquo;s see what we\u0026rsquo;ve got! Add the following line:  write.table(text, \u0026quot;output.txt\u0026quot;)\nand run it.\nSave your R script as \u0026ldquo;one-image-ocr.R\u0026rdquo;.\nLooping over many files at once  Grab a handful of images from the war diary and save them inside the folder you are working in, in a new subfolder (three or four are fine; I just right-clicked and save image on the urls at http://data2.archives.ca/e/e061/e001518034.jpg http://data2.archives.ca/e/e061/e001518035.jpg etc for the purposes of this recipe).  Now, we\u0026rsquo;re going to modify the first recipe to include a loop, and to apply the image modifications and to do the ocr to each image in turn. Make a new script, and then put into it which libraries you\u0026rsquo;re going to use. Run those lines.  1 2 3 4  # tell R which packages you need library(magick) library(magrittr) library(tesseract)   I put the files I wanted to work on into a subfolder called \u0026lsquo;many-pics\u0026rsquo;. Now we create a variable called \u0026lsquo;myfiles\u0026rsquo; into which we\u0026rsquo;re going to put the list of files held in our directory of files.  1 2  imgsource \u0026lt;- \u0026#34;many-pics\u0026#34; myfiles \u0026lt;- list.files(path = imgsource, pattern = \u0026#34;jpg\u0026#34;, full.names = TRUE)   Put these lines into your script, then run them. Over in the environment pane, you\u0026rsquo;ll see them get created, and you\u0026rsquo;ll see what\u0026rsquo;s inside them.\nNow the loop. Copy this into your script:  1 2 3 4 5 6 7 8 9 10  lapply(myfiles, function(i){ text \u0026lt;- image_read(i) %\u0026gt;% image_resize(\u0026#34;3000x\u0026#34;) %\u0026gt;% image_convert(type = \u0026#39;Grayscale\u0026#39;) %\u0026gt;% image_trim(fuzz = 40) %\u0026gt;% image_write(format = \u0026#39;png\u0026#39;, density = \u0026#39;300x300\u0026#39;) %\u0026gt;% tesseract::ocr() outfile \u0026lt;- paste(i,\u0026#34;-ocr.txt\u0026#34;,sep=\u0026#34;\u0026#34;) cat(text, file=outfile, sep=\u0026#34;\\n\u0026#34;)   Techically, this isn\u0026rsquo;t actually a loop. We\u0026rsquo;re just applying all of this image fixing and text extraction to each file in our myfiles variable, and then creating a unique text file appending -ocr.txt to the original filename. Put the cursor at the l in lapply, and then hit run; the machine will take some time to do its thing, but then\u0026hellip;\nNow imagine how much you\u0026rsquo;re missing when you do keyword searches of OCR\u0026rsquo;d documents\u0026hellip;\nSave your work.\nWhat about handwriting? Handwriting is a much more complicated problem, but in recent years machine learning has made enormous strides in this regard. I will point you to some documents I prepared for another class of mine if you want to explore this problem.\n\u0026lsquo;Detecting and Transcribing Handwriting with Microsoft Azure\u0026rsquo;\n","description":"instructions","id":22,"section":"week","tags":null,"title":"OCR","uri":"https://craftingdh.netlify.com/week/2/ocr/"},{"content":"This week\u0026rsquo;s bonus, gazetteers for keywords thing?\n","description":"Basic Tools","id":23,"section":"week","tags":null,"title":"This week's bonus","uri":"https://craftingdh.netlify.com/week/3/bonus/"},{"content":"Publish data with datasette to heroku\n","description":"Of Macroscopes and Microscopes","id":24,"section":"week","tags":null,"title":"This Week's Bonus","uri":"https://craftingdh.netlify.com/week/4/bonus/"},{"content":" static website with gh-pages static website with jekyll-now static website with expose link back to academic-kickstarter thing  ","description":"Telling the Compelling Story","id":25,"section":"week","tags":null,"title":"Static Websites","uri":"https://craftingdh.netlify.com/week/5/static-websites/"},{"content":" HIST3814O|DIGH3814O Summer 2020 Department of History, Carleton University This is a methods course about learning to use the huge variety of digitized historical resources available in the world, including some perhaps unconventional sources such as social media. You will learn some of the habits of doing born-digital work, including the doing of digital history as an outward facing public history.\nYou do not need to be \u0026lsquo;techy\u0026rsquo; to be successful in this course! You just need to be diligent, honest, and open. You will read, watch, listen to, and discuss the class materials via various online tools including Hypothes.is and Github (Speaking of Hypothes.is, highlight a word on this page and see what happens). We do not use cuLearn in the course. We work on the open web instead. Successful completion of this class involves doing a series of exercises each week designed to push you out of your comfort zone, AND to be a collegial and generous scholar engaging with, and helping your peers to achieve success. What is challenging for one student will not necessarily be challenging for another, and I expect you to push yourself and pull others along as you go. Thus open and honest reporting of what works and what hasn’t worked, is a meaningful aspect of this course. You don’t need to be techy to succeed, but you do need to be willing to embrace when things go ‘wrong’.\nIt\u0026rsquo;s super important that you try to complete the weekly exercises each week before moving onwards. Each week builds on the previous week\u0026rsquo;s work. In my experience, trying to complete this course in a compressed time frame is extremely difficult. Stay on task, complete one module a week. Work that is completed by the end of the week can expect formative feedback from me by the middle of the subsequent week. I prioritize responding to recent work, rather than overdue work. There is no grade penalty for overdue work, but you will miss out on feedback.\nThis course aims to change how you think about, and think with, digitized resources and digital tools. I am not trying to turn you into a coder. Rather, I am trying to turn you into a historian who is thoughtful and reflective about the ways digital tools transform what it is we know about the past and how we come to know it.\n","description":"what to tell your friends","id":26,"section":"docs","tags":null,"title":"1. Course Description","uri":"https://craftingdh.netlify.com/docs/1-coursedescription/"},{"content":"Outcomes  This course will enable you to analyze and assess historical documents, artifacts, and other primary sources through the lens of digital history methods, critically applied, and you will develop awareness of the ways digital tools change what it is possible to know about the past. At the same time, this ability will enable you to analyze and assess critically digital tools and methods from a historical perspective. Given that this is an online course, another outcome will be your ability to conduct such research independently. However, no one operates in a vacuum; digital historians collaborate to troubleshoot or develop technologies, and through open practices to data sharing and reuse, learn to build upon each others\u0026rsquo; work in a collaborative fashion. Another outcome will be the ability to translate the results of digital methods into historical argument. Digital work is often necessarily therefore a kind of public work, and a final outcome therefore will be a professionalized presence online.  Texts See the weekly work section. All readings are open access.\nReal Names Policy You do not need to use your real name or identity on any public-facing work that you do in this course. Nor do you need to explain to me that you wish to use a pseudonym. It is sufficient that you send an email to me with the following message:\n‘I would like to use the following username in all public-facing work: xxxxxxxx’\n…where xxxxx is the name you have selected. For safety’s sake, if you decide to use a pseudonym, do not use one that you have used on any other website or social media platform.\nWhen Life Intervenes There\u0026rsquo;s nothing we can\u0026rsquo;t roll with, in this class. That said, it is a compressed time frame: so if something comes up, just let me know:\nYou don\u0026rsquo;t have to share the details with me. It is enough for me to know that something has intervened. I trust you.\r When something comes up and this course has to move to the backburner, contact me and we can figure out something else to do, or something else that will help you be successful here. It\u0026rsquo;s our course - we can change things up as we need to.\n","description":"what you'll get out of this course","id":27,"section":"docs","tags":null,"title":"2. Learning Outcomes","uri":"https://craftingdh.netlify.com/docs/2-learning-outcomes/"},{"content":"Each week involves completing to the best of your ability a series of exercises; you will document your progress in a weekly log that you will keep online. Log entries are required to be completed by the Sunday evening at the end of the relevant work. A final reflection piece is due at the end of the course. See the assessment page for further details\nWeek 1, May 4 An overview of digital history\nWeek 2, May 11 Basic Tools\nWeek 3, May 19 Basic Tools Encore\nWeek 4, May 25 Of Macroscopes and Microscopes\nWeek 5, June 1 Telling the Compelling Story\nWeek 6, June 8 Bringing it all Together\nJune 16th: Exit Ticket Due The last thing you\u0026rsquo;ll do for this course\n","description":"what happens when, and where","id":28,"section":"docs","tags":null,"title":"3. Course Calendar","uri":"https://craftingdh.netlify.com/docs/3-schedule/"},{"content":"There is no midterm. There is no final exam.\r Weekly Exercises Each week, there are set exercises for you to attempt.\nWeekly work should be completed by the end of the relevant week.\nI am not looking for \u0026lsquo;correct\u0026rsquo; completion, or that you powered through x amount of them. I am, rather, looking for your evidence of thinking through the meaning of the process: what worked, what didn\u0026rsquo;t, why, and what that might mean for you as a historian. I am looking for you to tie your process explicitly to the readings. I am looking to see if the conversations you have with me or your peers (or indeed elsewhere on the web or in other courses) are causing you to reflect on the what/why/how/ of what you do.\nEvidence Therefore, I am looking for the following kinds of evidence (each week will specify what needs to be done):\n logs that keep track of what you actually tried reflection on that process engagement with the materials and your classmates (which might be demonstrated many different ways) evidence for your growth as a historian over this course  At the end of each week, you will provide to me through a form that can be found on each weekly page the links to your evidence for me to consider, by Sunday evening.\nI will return feedback to you within two or three days. I will write you a note giving you my perspective on what you\u0026rsquo;ve done (using the lens of the learning outcomes), and offering advice. Your weekly work will be assessed as \u0026lsquo;satisfactory\u0026rsquo; or \u0026lsquo;unsatisfactory\u0026rsquo;.\nThis feedback will also be mapped against the learning outcomes, so that you know how you are progressing throughout the course.\nThe Exit Ticket You will produce an \u0026lsquo;exit ticket\u0026rsquo; for me at the end of the course (open format) reflecting on where you started and where you\u0026rsquo;ve gotten to, and you will indicate how you feel you\u0026rsquo;ve done against the learning outcomes. The exit ticket is a summary assessment exercise that will pull all the different strings together into a strong cord. Everyone\u0026rsquo;s journey is different. Digital methods are more a matter of practice and time than they are of aptitude.\nYour final grade isn\u0026rsquo;t based on getting something \u0026lsquo;correct\u0026rsquo;. It\u0026rsquo;s based on your own assessment of your own journey.\r If you\u0026rsquo;ve never done digital work before, it might be that you never quite manage to get as many of the tech things working as you might\u0026rsquo;ve wanted: but you now know what you didn\u0026rsquo;t know before. That\u0026rsquo;s a win. You might be a computer science minor and the tech materials don\u0026rsquo;t present you with much challenge: but figuring out how to tell the compelling story was very difficult for you but you\u0026rsquo;re better at it now. Your \u0026lsquo;exit ticket\u0026rsquo; will explain to me your particular context, and it will point to the evidence that demonstrates how you\u0026rsquo;ve moved along from where you were at the beginning to where you are now.\nIf I agree with your assessment, then that is the grade you will receive. When I have disagreed in previous courses this has been, 9.5 times out of 10, to raise the grade: y\u0026rsquo;all are too hard on yourselves. If I have disagreed and felt that you\u0026rsquo;ve overstated things - if you were the 0.5 out of 10 - we would talk and come to an agreement.\nThe Exit Ticket should be submitted by the last day of the early summer term. If you should require more time, you need merely to let me know; no questions asked.\nGrading Remembering the learning outcomes,\n   Learning Outcome A B C D eg. Joe Q Student     1. analytical ability - - - - X   2. methodology - - - - -   3. collaboration - - - - X   4. argumentation - - - - X   5. professionalization - - - - -    \u0026hellip;5/5 would be an A, 4/5 would be a B, 3/5 would be a C, 2/5 a D.\nIn this example, based on my consideration of Joe Q Student\u0026rsquo;s evidence and the feedback I\u0026rsquo;d written him over the six weeks, it seemed to me that he did what he needed to do (satisfactorily) for 3 out of the 5 outcomes and so earned a C. However, his exit ticket might bring him up. Percentage Breakdown I am required by the University to provide a percentage breakdown.\nWeekly work = 80%\nFinal Exit ticket = 20%\nI reserve the right to adjust those percentages to take into account the particular circumstances of the student.\n","description":"grading and ungrading","id":29,"section":"docs","tags":null,"title":"4. Assessment","uri":"https://craftingdh.netlify.com/docs/4-assessment/"},{"content":"The following are the University regulations common to all History courses.\r COPIES OF WRITTEN WORK SUBMITTED Always retain for yourself a copy of all essays, term papers, written assignments or take-home tests submitted in your courses.\nPLAGIARISM The University Senate defines plagiarism as “presenting, whether intentionally or not, the ideas, expression of ideas or work of others as one’s own.” This can include:\n reproducing or paraphrasing portions of someone else’s published or unpublished material, regardless of the source, and presenting these as one’s own without proper citation or reference to the original source; submitting a take home examination, essay, laboratory report or other assignment written, in whole or in part, by someone else; using ideas or direct, verbatim quotations, or paraphrased material, concepts, or ideas without appropriate acknowledgment in any academic assignment; using another’s data or research findings; failing to acknowledge sources through the use of proper citations when using another’s works and/or failing to use quotation marks; handing in \u0026ldquo;substantially the same piece of work for academic credit more than once without prior written permission of the course instructor in which the submission occurs.\u0026rdquo;  Plagiarism is a serious offence which cannot be resolved directly with the course’s instructor. The Associate Dean of the Faculty conducts a rigorous investigation, including an interview with the student, when an instructor suspects a piece of work has been plagiarized. Penalties are not trivial. They can include a final grade of \u0026ldquo;F\u0026rdquo; for the course.\nCOURSE SHARING WEBSITES and COPYRIGHT To the degree that I am able, all original content on this course website is released under creative commons licensed. That means you may copy and share and reuse it, but you must attribute under the following terms - click through..\nSTATEMENT ON CLASS CONDUCT The Carleton University Human Rights Policies and Procedures affirm that all members of the University community share a responsibility to:\n promote equity and fairness, respect and value diversity, prevent discrimination and harassment, and preserve the freedom of its members to carry out responsibly their scholarly work without threat of interference.  Carleton University Equity Services states that \u0026lsquo;every member of the University community has a right to study, work and live in a safe environment free of discrimination or harassment\u0026rsquo;. [In May of 2001 Carleton University’s Senate and Board of Governors approved the Carleton University Human Rights Policies and Procedures. The establishment of these policies and procedures was the culmination of the efforts of the Presidential Advisory Committee on Human Rights and a Human Rights Implementation Committee.]\nGRADING SYSTEM Letter grades assigned in this course will have the following percentage equivalents:\n   Grade        A+ = 90-100 (12) B = 73-76 (8) C - = 60-62 (4) F= 0-49 (0) – Failure: no academic credit   A = 85-89 (11) B - = 70-72 (7)\tD+ = 57-59 (3)    A - = 80-84 (10) C+ = 67-69 (6) D = 53-56 (2)    B+ = 77-79 (9) C = 63-66 (5) D - = 50-52 (1)     The following additional final course grades may be assigned by instructors:\nDEF Official deferral of final exam (see \u0026ldquo;Petitions to Defer\u0026rdquo;)\nGNA Grade not available. This is used when there is an allegation of an academic offence. The notation is replaced with the appropriate grade for the course as soon as it is available.\nIP\tIn Progress – a notation (IP) assigned to a course by a faculty member when: At the undergraduate level, an undergraduate thesis or course has not been completed by the end of the period of registration.\nWDN\tWithdrawn. No academic credit, no impact on the CGPA. WDN is a permanent notation that appears on the official transcript for students who withdraw after the full fee adjustment date in each term (noted in the Academic Year section of the Calendar each term). Students may withdraw on or before the last day of classes.\nStanding in a course is determined by the course instructor subject to the approval of the Faculty Dean. This means that grades submitted by the instructor may be subject to revision. No grades are final until they have been approved by the Dean.\nWITHDRAWAL WITHOUT ACADEMIC PENALTY May 22, 2020: Last day for a full fee adjustment when withdrawing from early summer and full summer courses (financial withdrawal). Withdrawals after this date will result in a permanent notation of WDN on the official transcript.\nJune 16, 2020: Last day for academic withdrawal from early summer courses.\nJuly 17, 2020: Last day for a full fee adjustment when withdrawing from late summer courses (financial withdrawal).\nAugust 14, 2020: Last day for academic withdrawal from late summer and full summer courses and any other courses that end this term.\nREQUESTS FOR ACADEMIC ACCOMMODATIONS You may need special arrangements to meet your academic obligations during the term. For an accommodation request the processes are as follows:\nPregnancy obligation: write to the professor with any requests for academic accommodation during the first two weeks of class, or as soon as possible after the need for accommodation is known to exist. For more details see https://carleton.ca/equity/wp-content/uploads/Student-Guide-to-Academic-Accommodation.pdf\nReligious obligation: write to the professor with any requests for academic accommodation during the first two weeks of class, or as soon as possible after the need for accommodation is known to exist. For more details see https://carleton.ca/equity/wp-content/uploads/Student-Guide-to-Academic-Accommodation.pdf\nAccommodation for Student Activities: write to the professor with any requests for academic accommodation during the first two weeks of class, or as soon as possible after the need for accommodation is known to exist. For more details see https://carleton.ca/senate/wp-content/uploads/Accommodation-for-Student-Activities-1.pdf\nSurvivors of sexual violence: As a community, Carleton University is committed to maintaining a positive learning, working and living environment where sexual violence will not be tolerated, and is survivors are supported through academic accommodations as per Carleton\u0026rsquo;s Sexual Violence Policy. For more information about the services available at the university and to obtain information about sexual violence and/or support, visit: https://carleton.ca/sexual-violence-support/wp-content/uploads/Sexual-Violence-Policy-December-1-2016.pdf\nAcademic Accommodations for Students with Disabilities: The Paul Menton Centre for Students with Disabilities (PMC) provides services to students with Learning Disabilities (LD), psychiatric/mental health disabilities, Attention Deficit Hyperactivity Disorder (ADHD), Autism Spectrum Disorders (ASD), chronic medical conditions, and impairments in mobility, hearing, and vision. If you have a disability requiring academic accommodations in this course, please contact PMC at 613-520-6608 or pmc@carleton.ca for a formal evaluation. If you are already registered with the PMC, contact your PMC coordinator to send me your Letter of Accommodation at the beginning of the term, and no later than two weeks before the first in-class scheduled test or exam requiring accommodation (if applicable). After requesting accommodation from PMC, meet with me to ensure accommodation arrangements are made. Please consult the PMC website for the deadline to request accommodations for the formally-scheduled exam (if applicable).\nPETITIONS TO DEFER Students unable to write a final examination because of illness or other circumstances beyond their control or whose performance on an examination has been impaired by such circumstances may apply within five working days to the Registrar\u0026rsquo;s Office for permission to write a deferred examination. The request must be fully and specifically supported by a medical certificate or other relevant documentation. Only deferral petitions submitted to the Registrar\u0026rsquo;s Office will be considered.\nADDRESSES (613-520-2600, phone ext.)  Department of History (2828) 400 PA Registrar’s Office (3500) 300 Tory Academic Advising Centre (7850) 302 Tory Paul Menton Centre (6608) 500 Unicentre Centre for Student Academic Support – Study Skills, Writing Tutorials, Bounce Back (3822) 4th fl Library  Application for Graduation Deadlines\n Spring Graduation (June): April 1 Fall Graduation (November): September 1 Winter Graduation (February): December 1  ","description":"university rules","id":30,"section":"docs","tags":null,"title":"5. Common Regulations","uri":"https://craftingdh.netlify.com/docs/5-commonregs/"},{"content":"Dr. Graham can be found online at\nshawn dot graham at carleton dot ca\nor on Twitter at @electricarchae.\nHe will be present in our Crafting Digital History discord server every day.\nIf we ever get out of quarantine, and you\u0026rsquo;re in Ottawa, he often haunts the Library coffeeshop.\n","description":"how to find him","id":31,"section":"docs","tags":null,"title":"6. Contacting Dr. Graham","uri":"https://craftingdh.netlify.com/docs/6-contact/"},{"content":"This course originally was a face-to-face class, over 13 weeks. That let us get into the nitty-gritty of different approaches and platforms; it gave us the opportunity to have guest speakers; and most importantly, it gave us the time to really grapple with different kinds of historical \u0026lsquo;capta\u0026rsquo; (see Drucker on \u0026lsquo;capta versus data\u0026rsquo;). But, needs evolved and eventually the course moved fully online. Now only 6 weeks long, a lot of things have been cut, compressed, or rethought entirely. I do not aim for coverage. Rather, I am trying to help you learn the skills that you will need to uncover whatever aspect of digital history method and thought that will help you with your research goals. A big part of that is trying to teach how to deal with what might feel like \u0026lsquo;failure\u0026rsquo;, on first blush.\nSocial Contact Another problem with moving fully online was the isolation. Working with digital tools, especially when you\u0026rsquo;re not overly familiar with how they work - or even the underlying metaphors that would help you make sense of what\u0026rsquo;s going on - is frustrating. Bad enough when you have classmates you see twice a week and can at least complain with over coffee later; extremely awful when you\u0026rsquo;re on a bad internet connection and everyone thinks that you\u0026rsquo;re not really doing schoolwork.\nInitially, I used Slack as a way of trying to meet that need for human connection that makes learning meaningful. It worked, more or less, but if there was a conversation going on and you missed part of it, it could just feel overwhelming and impenetrable.\nAnd it was one more damned thing to install. One more damned thing to get a password for.\nI tried Zulipchat another year. Same problem again.\nThis year, as I write this, I\u0026rsquo;m trying Discord, for its voice and screensharing integration. We\u0026rsquo;ll see how that goes.\nThe Workbook I put all of the materials for the course into an online workbook, built from text files that used markdown conventions to indicate headings, links, images and so on. The website for the workbook would then be generated using mkdocs, a python library for generating static websites. It worked, but over the years I kept adding more and more to it, links would get broken or websites would go offline\u0026hellip; it was a lot of work to prune it, keep it up to date.\nAnd then COVID-19 happened.\nI normally have a lot of time to rethink what needs taught, to prune what has become useless, to add newer resources, newer thinking. But this time around, not so much. I put the older version of the course away, and started trying to build what I thought were the most useful elements: given everything else that is going on, what are the key things I think you ought to do in order to plant the seeds of your eventual engagement with digital history?\nThe result is this present website, which combines a number of features of the course that were previously spread across a number of locations. I have also pared down to a more limited number of skill-based exercises so that you have more time to think about the context (historiographical, theoretical) of their potential use. I offer more direction and less freedom-to-choose in terms of the work I think that needs to be done, but the trade off here is that you are more able to share what you are doing with your peers and to find help.\nWhich reminds me:\nDigital History is a team sport. You are never expected to power through all of this material on your own in heroic scholarly endeavor. If you need help, ask for help; if you can help, offer it. You are not alone.\r This website is built using Hugo, a static site builder. Static sites are quicker, more secure, and separate content from container, thus making them more sustainable. I write all of the content in individual text files, which I can then turn into whatever output - html, pdf, word doc - that I need. My writing is freed from subscription-based software that might lock it in. I push all of the text files onto github (you can see them here.) Then, I have netlify.com watch those files for any changes. When it spots changes, it uses Hugo to turn them into html, and serves them up at craftingdh.netlify.com.\nSome of the work we do requires working with the command line or the terminal of your computer; I also provide a virtual computer that you can access through your browser so that you don\u0026rsquo;t have to worry about configuring your particular machine to do any one task. This also allows me to write instructions once, and know that everyone will be able to do it (there are always differences between Mac and PC that trip us up). The virtual computer is provided by a service called Binder; I set up a folder on Github with the required bits-and-pieces (think of them as lego blocks) that are necessary for a particular task. I then point Binder at that folder, and it spins up a virtual computer with those pieces properly installed. It then gives me a URL that I can share with you - link on it, and boom! a computer in the cloud ready to go.\nAll of this is now under the \u0026lsquo;weekly work\u0026rsquo; part of this site. Take your time, annotate the parts that are confusing or troublesome with hypothes.is and you\u0026rsquo;ll do well.\nOne last thing I asked Twitter for its thoughts, as you do:\n.twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  5 top [method/skills] things students new to digital history should learn. Go!\n\u0026mdash; Shawn Graham (@electricarchaeo) March 28, 2020 \u0026hellip;follow the thread!\n","description":"how the course tech is built; how the course came to be","id":32,"section":"docs","tags":null,"title":"7. Colophon","uri":"https://craftingdh.netlify.com/docs/7-colophon/"},{"content":"Help! Things have gone wrong! Montparnasse Derailment, 1895\nThings are going to go wrong. Things are going to break. Instructions will seem vague or incomplete - or worse, I will have indeed forgotten to tell you something crucial.\nOr worse, I\u0026rsquo;ve made an assumption about your understanding, and left things unsaid that needed to be made explicit. There\u0026rsquo;s a lot of this, in the digital world, in fact.\nThis week, you learned a bit about Git and Github. Let\u0026rsquo;s look at a question on the q-and-a site, \u0026lsquo;Stackoverflow\u0026rsquo; here. Just scroll through that question, and look at some of the answers. Make a note of any terms or code or responses that make not an ounce of sense to you.\nIt can make you feel rather overwhelmed, rather quickly. And like most places on the internet, StackOverflow has its own culture, its own norms of expression and behaviour. People who are new can get roasted. That\u0026rsquo;s one of the reasons we have our own discord server, and a private reading group on Hypothesis: these are places for you to ask for help from a community that understands where you\u0026rsquo;re coming from because we\u0026rsquo;re all in the same headspace.\nSo, when things go wrong, the first thing to do is to find the community that understands where you\u0026rsquo;re coming from. I read and search StackOverflow all the time, but I rarely ask questions there. Instead, I write to trusted colleagues. And they in turn write to me.\nBut there are a couple of things we can do to make life easier.\nAsking good questions StackOverflow does have good advice on asking good questions. I will excerpt some of their advice:\n Write a title that summarizes the specific problem\u0026hellip; If you\u0026rsquo;re having trouble summarizing the problem, write the title last - sometimes writing the rest of the question first can make it easier to describe the problem.\n  Introduce the problem before you post any code [or a screenshot or a video clip]\u0026hellip;start by expanding on the summary you put in the title. Explain how you encountered the problem you\u0026rsquo;re trying to solve, and any difficulties that have prevented you from solving it yourself.\n  Help others reproduce the problem [SG: post the code, post a screenshot, post a video clip walk through]\n Please do this.\nEvery term, I receive dozens of emails with the subject line \u0026lsquo;help\u0026rsquo; and the message body \u0026lsquo;i tried it and it doesn\u0026rsquo;t work\u0026rsquo;. Sometimes, the message will also say \u0026lsquo;i worked on it for 3 hrs and it doesn\u0026rsquo;t work\u0026rsquo;.\nNone of that is helpful. Telling me that you worked on it for 3 hours just shows me that you ignored my messages about \u0026lsquo;if it doesn\u0026rsquo;t come after 30 minutes, take a break, ask for help\u0026rsquo;. So - let\u0026rsquo;s practice right now.\nWe\u0026rsquo;re going to make a git mistake.\nHere\u0026rsquo;s the situation:\n Imagine that you were working on your repo, wanting to update it from the command line - but you had to go away for a bit. When you come back, you discover your computer has run out of juice and shut down. Plugging it back in, none of your folders are open. You click on what you think is the right one and start to carry on\u0026hellip;.\n Right-click on any folder on your computer except the one(s) you created in the github exercise, and open a command prompt or a terminal there. Imagine I told you to commit your changes, like so: git commit -m \u0026quot;this is just a test\u0026quot;.\nDo that.\nWhat happened? Write a \u0026lsquo;help request\u0026rsquo;, using the guidelines above, and post it in the appropriate channel in our Discord, introducing it with an appropriate title (eg, \u0026lsquo;Demo Help Request\u0026rsquo;). Feel free to respond to a request with eg \u0026lsquo;Demo Help Response\u0026rsquo;.\nAnswering questions As the course progresses, you will have many opportunities to ask for help from me and from your peers - post these in our discord server in the appropriate channel.\nSometimes, you will see questions that you can answer. A few guidelines for answering questions:\n There are many different ways to solve these issues; someone might post a different way but that doesn\u0026rsquo;t mean that either of you are necessarily wrong. Read the question carefully. Request clarification if there are bits that the original poster didn\u0026rsquo;t make clear - help them to ask better questions. Use screenshots and screenvideo (I find screencastomatic handy in this regard) to show how things worked for you. Provide links to useful relevant material if you know of it. Assume the best of everyone: not everyone has the same fluency with these machines, and it takes a while to learn the language.  ","description":"instructions","id":33,"section":"week","tags":null,"title":"Asking for help","uri":"https://craftingdh.netlify.com/week/1/help/"},{"content":"Historian\u0026rsquo;s don\u0026rsquo;t deal with video very well. That is to say, we don\u0026rsquo;t have many tools for dealing with video as video, as a moving image, and analyzing with an eye towards the specific affordances of the medium (but see Arnold and Tilton\u0026rsquo;s \u0026lsquo;Distant Viewing\u0026rsquo; project, and their position paper.)\nBut we\u0026rsquo;re good with text. In this bonus exercise, you\u0026rsquo;ll download a video from youtube of Dr. Martin Luther King\u0026rsquo;s \u0026lsquo;I have a dream\u0026rsquo; speech (wikipedia), and use Google\u0026rsquo;s speech-to-text engine to generate a time-stamped transcript of the speech.\nNB. This works with historic audio recordings too, but of course, the better the audio quality, the better the transcript. You could even record yourself speaking and use this to make a transcript of audio notes.\nGet the code We\u0026rsquo;re going to use this repository by Alex Kras; you can read his original blog post describing his project here.\n  Open terminal or anaconda powershell, and make a new python environment with conda create -n audio python=3.7 anaconda\n  activate your environment: conda activate audio\n  get the repository with: git clone https://github.com/akras14/speech-to-text.git\n  change directories so that you\u0026rsquo;re in that repo: cd speech-to-text\n  install the necessary bits-and-pieces that Kras put into his requirements file: pip install -r requirements.txt\n  Getting access to the Google API Follow Kras\u0026rsquo;s instructions to get an api key to access the speech-to-text engine:\n Sign up for the free tier and then sign in to Google Cloud Console Click “APIs \u0026amp; Services” Click “Credentials” Click “Create Credentials” Select “Service Account Key” Under “Service Account” select “New service account” Name service (whatever you’d like) Select Role: “Project” -\u0026gt; “Owner” Leave “JSON” option selected Click “Create” Save generated API key file Rename file to api-key.json  The file api-key.json needs to be saved inside your copy of the speech-to-text folder (eg, \\speech-to-text\\api-key.json). Note that Google sometimes changes up its interface a bit, and so the exact sequence of clicks might not be the same as described above.\nSome video utilities   Download and install youtube-dl or install it from the command line:\npip install --upgrade youtube_dl.\nIf you try the command line and get an error about not having permission to do this, try\nsudo pip install --upgrade youtube_dl\nThis will require you to enter your computer username and password. Note that when you enter the password, the cursor won\u0026rsquo;t move. This is old-school security in action\u0026hellip;\n  Download and install ffmpeg.\nOn a mac - if you haven\u0026rsquo;t already, get homebrew first (a package manager for downloading and installing things like this) here. That website gives you a command to run in your terminal to download and install homebrew. (But if you successfully installed Brew when you did the wget work, then you just need to do the brew install command). Then, when homebrew is installed: brew install ffmpeg\n  On a pc: download and install from here\nNow let\u0026rsquo;s do this!  There\u0026rsquo;s a copy of the \u0026lsquo;I have a dream\u0026rsquo; speech uploaded by this user at: https://www.youtube.com/watch?v=I47Y6VHc3Ms. Note the bit after ?v=. That\u0026rsquo;s the id of the video we\u0026rsquo;re after. There are several versions of each video on youtube, to account for the different kinds of devices and resolution and so on. We\u0026rsquo;ll use youtube-dl to examine the different versions of this video, so that we can find the smallest one. At the command prompt, type youtube-dl -F I47Y6VHc3Ms The -F (upper case!) tells youtube-dl to go grab all of the info and print it out for us. Each line is a different version of the video, and each line has a unique number id. We look for the line that tells us which version is smallest. Today, that\u0026rsquo;s line 249 (notice that it also tells you that this is just the audio only). So now we tell youtube-dl to download only that version: youtube-dl -f 249 I47Y6VHc3Ms. The -f (lower case!) flag lets us select the line number we want, and then the ID string tells youtube which video we\u0026rsquo;re after. Use your file explorer to rename the file that you just downloaded to something sensible; I changed mine to \u0026lsquo;mlk.webm\u0026rsquo;. Now we\u0026rsquo;ll convert the file to a .wav file with the ffmpeg command: ffmpeg -i mlk.webm mlk.wav Move the file into the /source folder. Now we\u0026rsquo;re ready to chop the file into 30 second increments. Here we go: ffmpeg -i source/mlk.wav -f segment -segment_time 30 -c copy parts/out%09d.wav But before we pass those to google, note that files that contain dead air or nothing that is recognizable as speech can break things. Listen to the first two or three files you just created (in your file explorer, click on them). Delete the ones that are dead air. \u0026hellip;and now pass on the remaining filesto Google for processing! Make sure you\u0026rsquo;re in the correct location (eg, the speech-to-text folder) and type python slow.py \u0026gt; results.txt  A little progress bar will appear, and your code is passing your files one at a time up to google for processing; google is sending back to you the text! When it\u0026rsquo;s done, just open up the results.txt file.\nIf you have audio from other sources you\u0026rsquo;d like to try, just follow the pattern for converting it to .wav format, place it in the correct place (\\source), clean out the \\parts subdirectory, modify the command in step 7 with your own file name, and away you\u0026rsquo;ll go!\n","description":"instructions","id":34,"section":"week","tags":null,"title":"This week's bonus","uri":"https://craftingdh.netlify.com/week/2/bonus/"},{"content":"The Last Bit Do Reflect Submit work You can submit the link to your work on this form\n","description":"Final Submission Instructions","id":35,"section":"week","tags":null,"title":"Final Submission Instructions","uri":"https://craftingdh.netlify.com/week/6-5/instructions/"},{"content":" exhibit with Wax Omeka - reclaimhosting, links to tutorials Neatline - links to tutorials  ","description":"Telling the Compelling Story","id":36,"section":"week","tags":null,"title":"This Week's Bonus","uri":"https://craftingdh.netlify.com/week/5/bonus/"},{"content":"Click title to see the full Post\nLorem est tota propiore conpellat pectoribus de\npectora summo. Redit teque digerit hominumque toris verebor lumina non cervice\nsubde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc\ncaluere tempus\ninhospita parcite confusaque translucet patri vestro qui optatis\nlumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus\nsilentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria\ntractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et  Vagus elidunt \nThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra\ndicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere\nfurit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli\nLelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare\nEchionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert\nausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae\nvulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem\nPropoetides parte.\n","description":"","id":37,"section":"blog","tags":null,"title":"Placeholder Text","uri":"https://craftingdh.netlify.com/blog/placeholder/"}]